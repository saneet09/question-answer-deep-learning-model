{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "functiongetanswers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7daHQIFONH2",
        "colab_type": "code",
        "outputId": "19e655a4-a4f5-4075-ac32-7fffdf1e9b68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install keras_metrics\n",
        "!pip install extra-keras-metrics\n",
        "!pip install keras-self-attention\n",
        "!pip install -U gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.17.5)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n",
            "Collecting extra-keras-metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/82/0f/b3b2ab62df1b85f753d9a8f0eb29f2e333d085d75a160751b1591be18053/extra_keras_metrics-1.3.1.tar.gz\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from extra-keras-metrics) (2.2.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from extra-keras-metrics) (4.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.17.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->extra-keras-metrics) (1.4.1)\n",
            "Building wheels for collected packages: extra-keras-metrics\n",
            "  Building wheel for extra-keras-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for extra-keras-metrics: filename=extra_keras_metrics-1.3.1-cp36-none-any.whl size=13091 sha256=75bf083ffe09bc6f99c2ddaa569006f8250e98ae4c75f45c817f3af818ebed50\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/f1/b4/a9f81578416b99274b6d5b34fdc92d9bd82b6be99efa965b17\n",
            "Successfully built extra-keras-metrics\n",
            "Installing collected packages: extra-keras-metrics\n",
            "Successfully installed extra-keras-metrics-1.3.1\n",
            "Collecting keras-self-attention\n",
            "  Downloading https://files.pythonhosted.org/packages/44/3e/eb1a7c7545eede073ceda2f5d78442b6cad33b5b750d7f0742866907c34b/keras-self-attention-0.42.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.17.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.2.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.42.0-cp36-none-any.whl size=17296 sha256=f8fa0371485d195b8ab21172a95c11f15978e07845aeb33821810864cb2b6629\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/05/a0/99c0cf60d383f0494e10eca2b238ea98faca9a1fe03cac2894\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.42.0\n",
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/dd/112bd4258cee11e0baaaba064060eb156475a42362e59e3ff28e7ca2d29d/gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 73.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
            "Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (1.11.15)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.8.1->gensim) (1.14.15)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.8.1->gensim) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
            "Installing collected packages: gensim\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVfzWuIJLSdU",
        "colab_type": "code",
        "outputId": "4f24c090-daca-49b2-b0d7-82ee38c641d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Concatenate, LSTM, Dense, Conv1D, MaxPooling1D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Flatten\n",
        "import keras\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from tensorboardcolab import *\n",
        "from keras.callbacks import ModelCheckpoint,TensorBoard,ReduceLROnPlateau, EarlyStopping\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import keras_metrics as km\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from gensim.models import KeyedVectors\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import class_weight\n",
        "from keras.layers import Input,Bidirectional\n",
        "from keras.layers import LSTM,Input, dot, Lambda, Dense, Dropout,CuDNNLSTM, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
        "from keras.layers import Dot\n",
        "from sklearn.metrics import label_ranking_average_precision_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSHiIro6LSde",
        "colab_type": "code",
        "outputId": "a0eb7123-417c-44a7-88f9-f6c25f000f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRfgTlG9oXG1",
        "colab_type": "text"
      },
      "source": [
        "# Predictions of all answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB-XYZP9LSds",
        "colab_type": "code",
        "outputId": "efa7405f-a04b-4351-910f-33a46c7c294a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        " from keras.models import model_from_json\n",
        "# load json and create model\n",
        "json_file = open('/content/drive/My Drive/seach/maybefinal/final_model50.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/content/drive/My Drive/seach/maybefinal/final_model50.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4KmJfRQnpt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d70FhOQjnqW-",
        "colab_type": "text"
      },
      "source": [
        "# Search Engine:\n",
        "Where a question is passed and top 5 answers depending on prediction have been sorted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9IZ6j48upg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_fun_3(question):\n",
        "  df_csv = pd.read_csv('/content/drive/My Drive/seach/data.tsv', names=['ansindex', 'question', 'answer','anslabel','ans_no'],sep='\\t')\n",
        "  stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "                    \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his','himself', \\\n",
        "                    'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them','their',\\\n",
        "                    'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\",'these', 'those', \\\n",
        "                    'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having','do', 'does', \\\n",
        "                    'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "                    'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during','before', 'after',\\\n",
        "                    'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under','again', 'further',\\\n",
        "                    'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "                    'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "                    's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "                    've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "                    \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\"mightn't\", 'mustn',\\\n",
        "                    \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn',\\\n",
        "                    \"wasn't\", 'weren', \"weren't\",'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
        "  def decontracted(phrase):\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "        # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase\n",
        "  \n",
        "  \n",
        "  def preprocess_text(text_data):\n",
        "    preprocessed_text = []\n",
        "    # tqdm is for printing the status bar\n",
        "    for sentance in tqdm(text_data):\n",
        "        sent = decontracted(sentance)\n",
        "        sent = sent.replace('\\\\r', ' ')\n",
        "        sent = sent.replace('\\\\n', ' ')\n",
        "        sent = sent.replace('\\\\\"', ' ')\n",
        "        sent = sent.replace(\"'\", \"\")\n",
        "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "        # https://gist.github.com/sebleier/554280\n",
        "        sent = ' '.join(e for e in sent.split())\n",
        "        preprocessed_text.append(sent.lower().strip())\n",
        "    return preprocessed_text\n",
        "  \n",
        "  \n",
        "  def preprocess_text1(text_data):\n",
        "    preprocessed_text = []\n",
        "    # tqdm is for printing the status bar\n",
        "    for sentance in tqdm(text_data):\n",
        "        sent = decontracted(sentance)\n",
        "        sent = sent.replace('\\\\r', ' ')\n",
        "        sent = sent.replace('\\\\n', ' ')\n",
        "        sent = sent.replace('\\\\\"', ' ')\n",
        "        sent = sent.replace(\"'\", \"\")\n",
        "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "        # https://gist.github.com/sebleier/554280\n",
        "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
        "        preprocessed_text.append(sent.lower().strip())\n",
        "    return preprocessed_text\n",
        "  \n",
        "  \n",
        "  \n",
        "  preprocessed_q= preprocess_text(df_csv['question'].values)\n",
        "  preprocessed_a= preprocess_text1(df_csv['answer'].values)\n",
        "  df_csv['clean_answer']=preprocessed_a\n",
        "  df_csv['clean_question']=preprocessed_q\n",
        "  df_csv.drop(['answer','question'],axis=1,inplace=True)\n",
        "  df_csv.sort_values(by=['clean_question'])\n",
        "  \n",
        "  \n",
        "  #input\n",
        "  q=preprocess_text(question)\n",
        "  \n",
        "  \n",
        "  \n",
        "  answer=[]\n",
        "  #question=['average number of lightning strikes per day']\n",
        "  #q=preprocess_text(question)\n",
        "  for index,row in df_csv.iterrows():\n",
        "    if(row[\"clean_question\"]==q[0]):\n",
        "      #print(len(answer))\n",
        "      answer.append(row[\"clean_answer\"])\n",
        "      \n",
        "          \n",
        "  \n",
        "  questions = np.tile(question, (len(answer), 1)) \n",
        "  flat_ques = [item for sublist in questions for item in sublist]  \n",
        "  \n",
        "  \n",
        "  #, Word2Vec\n",
        "\n",
        "#currently using gensim's default word2vec pretrained model, trained on googlenews data. \n",
        "#todo: train on wikiqa if the results are crap. \n",
        "\n",
        "  w2vmodel = KeyedVectors.load_word2vec_format('/content/drive/My Drive/vector/GoogleNews-vectors-negative300-SLIM.bin.gz', binary=True)\n",
        "  \n",
        "  wvdict = w2vmodel.wv.vocab\n",
        "  \n",
        "  vocab_size = len(w2vmodel.index2word) + 1\n",
        "  \n",
        "  \n",
        "  #make embedding matrix\n",
        "  embedding_matrix = np.zeros((vocab_size, 300))\n",
        "  for i in range(len(wvdict)):\n",
        "    embedding_vector = w2vmodel.wv[w2vmodel.wv.index2word[i]]\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "      \n",
        "      \n",
        "  def SEQ_token_and_pad(sequences, max_seq_length):\n",
        "    encoded_seqs = []\n",
        "    for qa in sequences:\n",
        "      encoded_qa = []\n",
        "      tokenized_qa = qa.split()\n",
        "      for word in tokenized_qa:\n",
        "        index_to_append = vocab_size - 1\n",
        "      \n",
        "        if word in wvdict.keys():\n",
        "          index_to_append = w2vmodel.vocab[word].index\n",
        "        encoded_qa.append(index_to_append)\n",
        "    \n",
        "      encoded_seqs.append(encoded_qa)\n",
        "    padded_seqs = pad_sequences(encoded_seqs, maxlen = max_seq_length, padding=\"post\", value = vocab_size - 1)\n",
        "    return padded_seqs      \n",
        "  \n",
        "  max_hidden_length=161\n",
        "  \n",
        "  \n",
        "  padded_test_questions1 = SEQ_token_and_pad(flat_ques, max_hidden_length)\n",
        "  padded_test_answers1 = SEQ_token_and_pad(answer, max_hidden_length)\n",
        "  prob=loaded_model.predict_on_batch([padded_test_questions1, padded_test_answers1])\n",
        "  p=[el[1] for el in prob]\n",
        "  df = pd.DataFrame(answer,columns =['Answer'])\n",
        "  df['prob']=p\n",
        "  df=df.sort_values(by=['prob'],ascending=False)\n",
        "  print(\"top 5 high predicted answers\")\n",
        "  df=df.head(5)\n",
        "  return df\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "   \n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPtIq2wRUX-p",
        "colab_type": "code",
        "outputId": "d65f203c-2288-4537-f5a6-c5212a5e651b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "question=['symptoms of a dying mouse']\n",
        "df=final_fun_3(question)\n",
        "df\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5241880/5241880 [01:01<00:00, 84656.15it/s]\n",
            "100%|██████████| 5241880/5241880 [03:50<00:00, 22752.27it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 2786.91it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "top 5 high predicted answers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Answer</th>\n",
              "      <th>prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>symptoms similar mouse much worse condition 1 ...</td>\n",
              "      <td>0.909723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>symptoms dog cat poisoning symptoms poisoned p...</td>\n",
              "      <td>0.909513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>symptoms similar mouse much worse condition ru...</td>\n",
              "      <td>0.890835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>symptoms mites include 1 excessive scratching ...</td>\n",
              "      <td>0.747989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>depending poison ingested poisoned dog cat gas...</td>\n",
              "      <td>0.745571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Answer      prob\n",
              "6  symptoms similar mouse much worse condition 1 ...  0.909723\n",
              "2  symptoms dog cat poisoning symptoms poisoned p...  0.909513\n",
              "5  symptoms similar mouse much worse condition ru...  0.890835\n",
              "1  symptoms mites include 1 excessive scratching ...  0.747989\n",
              "7  depending poison ingested poisoned dog cat gas...  0.745571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "930RQ6rHYDWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BvKQNsaYDUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR66an00YDQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}